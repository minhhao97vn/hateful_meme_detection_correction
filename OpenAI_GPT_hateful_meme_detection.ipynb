{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ec864-6fdb-4575-925f-ae8f88c4a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai scikit-learn pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c287b-57fd-44e3-a082-25de47b61524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d653b1ef-e422-4590-9a13-95c3bc1bb8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='<openai-api-key>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a81053-82cc-4c85-9a61-fa9076010bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download link for dataset\n",
    "https://uark-my.sharepoint.com/:u:/g/personal/haovan_uark_edu/EU3T0FTfNTtBhKNNMo0ZHW0BEn1ZouV9wd1SrcSkW9csBw?e=MESUhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9daec2-596e-4f98-8a48-e72db0bb4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/haovan/hateful_memes/test_unseen\" + '.jsonl', 'r') as file:\n",
    "    test_data_meta = list(file)\n",
    "\n",
    "img_dir = '/home/haovan/hateful_memes/'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f858ac5-4d9d-43b5-b879-f4e4410617b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320f152-ab29-490b-b39f-ce9b3b069bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(image_path, new_height = 150):\n",
    "    img = PIL.Image.open(image_path)\n",
    "    ratio = img.size[1] / new_height\n",
    "    new_width = img.size[0] / ratio\n",
    "    img = img.resize((int(new_width), int(new_height)))\n",
    "    img.save(img_dir+\"/scaled_img/\"+test_sample['img'].split(\"/\")[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5229d0-6148-49f9-a474-8ad97ef7a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, json_str in enumerate(test_data_meta):\n",
    "    test_sample = json.loads(json_str)\n",
    "    image_path = img_dir+test_sample['img']\n",
    "    scale_image(image_path, new_height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc0677-cf1f-4d01-a5fa-d012ae9cf9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = lambda ocr_text: f\"\"\"Hatefulness definition: Hate speech is strictly defined as a direct or indirect attack on people based on characteristics, including ethnicity, race, nationality, immigration status, religion, caste, sex, gender identity, sexual orientation, disability, or disease. The definition of attack includes violent or dehumanizing speech, statements of inferiority, and calls for exclusion or segregation. Mocking hate crime is also considered hate speech.\n",
    "# Classification criteria: A meme is considered hateful if either the image or text is hateful on its own. A meme is also considered hateful if both the image and text are not hateful individually, but together convey a hateful message. If neither the image nor text is hateful, and they don't create a hateful meaning together, the meme is not hateful.\n",
    "\n",
    "# You consider visual and textual meanings to classify the meme as hateful or non-hateful based on the hatefulness definition and classification criteria.\n",
    "# The text written in the image: \"{ocr_text}\"\n",
    "# After giving a short explanation, provide the answer with following format:\n",
    "# Classification:\n",
    "# Probability of the meme being hateful (from 0 to 1):\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0343a-dec0-404b-82ab-c79b3c161d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = lambda ocr_text: f\"\"\"Hatefulness definition: Hate speech is strictly defined as a direct or indirect attack on people based on characteristics, including ethnicity, race, nationality, immigration status, religion, caste, sex, gender identity, sexual orientation, disability, or disease. The definition of attack includes violent or dehumanizing speech, statements of inferiority, and calls for exclusion or segregation. Mocking hate crime is also considered hate speech.\n",
    "Classification criteria: A meme is considered hateful if either the image or text is hateful on its own. A meme is also considered hateful if both the image and text are not hateful individually, but together convey a hateful message. If neither the image nor text is hateful, and they don't create a hateful meaning together, the meme is not hateful.\n",
    "\n",
    "You consider visual and textual meanings to classify the meme as hateful or non-hateful based on the hatefulness definition and classification criteria.\n",
    "After giving a short explanation, provide the answer with following format:\n",
    "Classification:\n",
    "Probability of the meme being hateful (from 0 to 1):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54124c-8a86-4576-b1d7-cbc2ac5e8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_processed_idx = -1\n",
    "unprocessed_ids = []\n",
    "responses = []\n",
    "full_responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d5633-88c2-4a4f-9189-ba83c4f21838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, json_str in enumerate(test_data_meta):\n",
    "    if idx <= last_processed_idx:\n",
    "        continue\n",
    "    test_sample = json.loads(json_str)\n",
    "    image_path = img_dir+\"/scaled_img/\"+test_sample['img'].split(\"/\")[-1]\n",
    "\n",
    "    base64_image = encode_image(image_path)\n",
    "    print(f\"Processing image: {test_sample['img']}, actual label: {test_sample['label']}\")\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "          model=\"gpt-4o\",\n",
    "          messages=[\n",
    "            {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\", \n",
    "                    \"text\": prompt(test_sample['text'])\n",
    "                },\n",
    "                {\n",
    "                  \"type\": \"image_url\",\n",
    "                  \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                  },\n",
    "                },\n",
    "              ],\n",
    "            }\n",
    "          ],\n",
    "          max_tokens=300,\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        full_responses.append(response.choices[0])\n",
    "    except Exception as e:\n",
    "        unprocessed_ids.append(test_sample['img'])\n",
    "        answer = \"ERROR WITH REQUEST\"\n",
    "        full_responses.append(e)\n",
    "        \n",
    "    responses.append(answer)\n",
    "    last_processed_idx = idx\n",
    "    print(answer)\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57cd5ba-6f03-4715-af35-c2db8b4d8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of responses: {len(responses)}\")\n",
    "print(f\"Number of failed responses: {len(unprocessed_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aad6f2-7a79-4b81-82c9-92da7cf662fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc1e74-2cf2-4ba7-912e-5a0f1eefa71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "now_time = datetime.now()\n",
    "\n",
    "file_name  = f'results_gpt4o_unseen_test_{now_time.strftime(\"%H_%M_%S__%d_%m_%Y\")}.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump({\"responses\": responses, \"unprocessed_ids\": unprocessed_ids}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd4ef1-40e2-4e7d-9917-595d34047a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    responses = data['responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73372935-d52f-479e-9a04-db1dd2e76511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "actuals = []\n",
    "predictions = []\n",
    "prob_list = []\n",
    "threshold = 0.5\n",
    "for idx, json_str in enumerate(test_data_meta):\n",
    "    test_sample = json.loads(json_str)\n",
    "    actual_class = test_sample['label']\n",
    "    actuals.append(actual_class)\n",
    "\n",
    "    lower_response = responses[idx].lower()\n",
    "    all_found_vals = re.findall(\"probability of the meme being hateful.*?\\:.*?\\n?[0-9]+\\.?[0-9]*.*?\", lower_response)\n",
    "    if len(all_found_vals) == 0:\n",
    "        is_hateful = False\n",
    "        hateful_keywords = [\"classification: hateful\", \"classified as hateful\"]\n",
    "        print(f'>>>>> Could not find probability in response - Idx: {idx} - Res: {lower_response}')\n",
    "        for kw in hateful_keywords:\n",
    "            if kw in lower_response:\n",
    "                is_hateful = True\n",
    "                break\n",
    "        if is_hateful:\n",
    "            predicted_class = 1\n",
    "            prob = 1.0\n",
    "        else:\n",
    "            predicted_class = 0\n",
    "            prob = 0.0\n",
    "        print(f'Assigned probability: {prob} <<<<<\\n\\n' )\n",
    "    else:\n",
    "        num_str = re.sub('[^0-9\\.]', '', (all_found_vals[0].split(\" \"))[-1])\n",
    "        if num_str[-1] == '.':\n",
    "            num_str = num_str[:-1]\n",
    "        if float(num_str) >= threshold:\n",
    "            predicted_class = 1\n",
    "        else:\n",
    "            predicted_class = 0\n",
    "        prob = float(num_str)\n",
    "    prob_list.append(prob)\n",
    "    predictions.append(predicted_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5febb5d-8cc0-4c89-91f5-c1482d235c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(np.array(actuals) == np.array(predictions))\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"AUROC: {roc_auc_score(actuals, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78fcf25-3777-436a-90c4-534591615fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff541f-ad2c-4047-9dc3-69b0bd597bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
