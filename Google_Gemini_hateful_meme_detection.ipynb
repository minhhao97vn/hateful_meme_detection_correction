{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff402f-77d4-4224-bd6c-b55fa3898426",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai\n",
    "!pip install pillow scikit-learn pickle  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd34161-1353-4bb2-93dc-c972ec809150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972b37b8-24c4-4665-94a6-0f74b7eaa040",
   "metadata": {},
   "source": [
    "### Download link for dataset\n",
    "https://uark-my.sharepoint.com/:u:/g/personal/haovan_uark_edu/EU3T0FTfNTtBhKNNMo0ZHW0BEn1ZouV9wd1SrcSkW9csBw?e=MESUhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663d081-f0de-4a9e-8e2b-1beb9db5fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key='<gemini-api-key>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6ef0a9-f80c-405d-aafd-032617ac75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b08a4c-ee81-488e-a240-7c0e5c5a4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_settings = [{\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                   {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"}, \n",
    "                   {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                   {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b164c54-4d74-4a39-be57-0b2f77e4dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash-latest', safety_settings = safety_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454ca94-52c7-4a10-b632-1478c7b6eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import json\n",
    "\n",
    "with open(\"/hateful_memes/test_seen\" + '.jsonl', 'r') as file:\n",
    "    test_data_meta = list(file)\n",
    "\n",
    "img_dir = '/hateful_memes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf207b-77d2-47a7-baa5-56c753ae2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = lambda ocr_text: f\"\"\"Hatefulness definition: Hate speech is strictly defined as a direct or indirect attack on people based on characteristics, including ethnicity, race, nationality, immigration status, religion, caste, sex, gender identity, sexual orientation, disability, or disease. The definition of attack includes violent or dehumanizing speech, statements of inferiority, and calls for exclusion or segregation. Mocking hate crime is also considered hate speech.\n",
    "# Classification criteria: A meme is considered hateful if either the image or text is hateful on its own. A meme is also considered hateful if both the image and text are not hateful individually, but together convey a hateful message. If neither the image nor text is hateful, and they don't create a hateful meaning together, the meme is not hateful.\n",
    "\n",
    "# You consider visual and textual meanings to classify the meme as hateful or non-hateful based on the hatefulness definition and classification criteria.\n",
    "# The text written in the image: \"{ocr_text}\"\n",
    "# After giving a short explanation, provide the answer with following format:\n",
    "# Classification:\n",
    "# Probability of the meme being hateful (from 0 to 1):\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f2d81-e8cb-45c0-8e54-8e52d0a1bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = lambda ocr_text: f\"\"\"Hatefulness definition: Hate speech is strictly defined as a direct or indirect attack on people based on characteristics, including ethnicity, race, nationality, immigration status, religion, caste, sex, gender identity, sexual orientation, disability, or disease. The definition of attack includes violent or dehumanizing speech, statements of inferiority, and calls for exclusion or segregation. Mocking hate crime is also considered hate speech.\n",
    "Classification criteria: A meme is considered hateful if either the image or text is hateful on its own. A meme is also considered hateful if both the image and text are not hateful individually, but together convey a hateful message. If neither the image nor text is hateful, and they don't create a hateful meaning together, the meme is not hateful.\n",
    "\n",
    "You consider visual and textual meanings to classify the meme as hateful or non-hateful based on the hatefulness definition and classification criteria.\n",
    "After giving a short explanation, provide the answer with following format:\n",
    "Classification:\n",
    "Probability of the meme being hateful (from 0 to 1):\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02eb641-c74c-4c76-90fb-7eadc822974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_processed_idx = -1\n",
    "unprocessed_ids = []\n",
    "responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c5184-4824-484a-9d1a-897ddde127f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, json_str in enumerate(test_data_meta[:50]):\n",
    "    if idx <= last_processed_idx:\n",
    "        continue\n",
    "    test_sample = json.loads(json_str)\n",
    "    image_path = img_dir + test_sample['img']\n",
    "    img = PIL.Image.open(image_path)\n",
    "    print(f\"Processing image: {test_sample['img']}, actual label: {test_sample['label']}\")\n",
    "    \n",
    "    response = model.generate_content([img, prompt(test_sample['text'])])\n",
    "    try:\n",
    "        answer = response.text\n",
    "    except Exception as e:\n",
    "        unprocessed_ids.append(test_sample['img'])\n",
    "        answer = \"MODEL ERROR\"\n",
    "    responses.append(answer)\n",
    "    last_processed_idx = idx\n",
    "    print(answer)\n",
    "    print()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad512026-da42-4e1a-8f5c-cdd55f9784b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of responses: {len(responses)}')\n",
    "print(f'Number of failed responses: {len(unprocessed_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdf905-df36-4423-809f-30150a299504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "now_time = datetime.now()\n",
    "\n",
    "file_name  = f'results_gemini_seen_test_{now_time.strftime(\"%H_%M_%S__%d_%m_%Y\")}.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump({\"responses\": responses, \"unprocessed_ids\": unprocessed_ids}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03939acb-c035-4d47-9085-21f8b4fceecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    responses = data['responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826fd3f-8aa9-4e79-a17d-ff1125a2392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = []\n",
    "predictions = []\n",
    "prob_list = []\n",
    "threshold = 0.5\n",
    "\n",
    "for idx, json_str in enumerate(test_data_meta):\n",
    "    test_sample = json.loads(json_str)\n",
    "    actual = test_sample['label']\n",
    "    actuals.append(actual)\n",
    "\n",
    "    lower_response = responses[idx].lower()\n",
    "    all_found_vals = re.findall(\"probability of the meme being hateful.*?\\:.*?\\n?[0-9]+\\.?[0-9]*.*?\", lower_response)\n",
    "    \n",
    "    if len(all_found_vals) == 0:\n",
    "        hateful_keywords = [\"classification: hateful\", \"classified as hateful\"]\n",
    "        print(f'>>>>> Could not find probability in response - Idx: {idx} - Res: {lower_response}')\n",
    "\n",
    "        is_hateful = False\n",
    "        for kw in hateful_keywords:\n",
    "            if kw in lower_response:\n",
    "                is_hateful = True\n",
    "                break\n",
    "        if is_hateful:\n",
    "            predicted_class = 1\n",
    "            prob = 1.0\n",
    "        else:\n",
    "            predicted_class = 0\n",
    "            prob = 0.0\n",
    "        print(f'Assigned probability: {prob} <<<<<\\n\\n' )\n",
    "    else:\n",
    "        num_str = re.sub('[^0-9\\.]', '', (all_found_vals[0].split(\" \"))[-1])\n",
    "        if num_str[-1] == '.':\n",
    "            num_str = num_str[:-1]\n",
    "        if float(num_str) >= threshold:\n",
    "            predicted_class = 1\n",
    "        else:\n",
    "            predicted_class = 0\n",
    "        prob = float(num_str)\n",
    "    prob_list.append(prob)\n",
    "    predictions.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3020b2-d12e-4a85-8a15-1c476fa6d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(np.array(actuals) == np.array(predictions))\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"AUROC: {roc_auc_score(actuals, prob_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef71a36-506d-46b5-b712-d8dd77381d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
